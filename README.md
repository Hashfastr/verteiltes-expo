# verteiltes
Distributed computing system written in C, that computes prime numbers.
For science expo 2017
by Sylvain Jones

	This project was done in order to develop a distributed computing system, and measure how it fairs against normal, standard methods of computing. This was done by writing a client-server program pair in C for linux systems with networking tools. The efficiency of the different computing methods were tested by computing a set amount of prime numbers, and measuring the time it took for each system to compute that amount. Tests were also conducted to determine if cooling systems such as a fan affected the tests. The Hypothesis for this project is as follows; By writing a different computational systems in C and weighing their usefulness by setting them to compute the same algorithm for computing prime number we will see that the network computation system will prevail in terms of computation speed. This is due to the amount of cpu cores the network system has available to it compared to the other ‘regular’ systems of computation.
The normal standards of computing that were compared to the distributed system were single core and modern core. The single core system was a simple C program that utilized the same prime-number computation method that the network computing uses, and ran on one core of the raspberry pis. The modern core system was the same program as the single core, but compiled and ran on the Server.
Data collection was done by repeating the computation systems by looping the various systems with a bash script, each loThe distributed computing system was done using a beowulf cluster of four Raspberry pi 3s, each running 4 clients, a server that managed all the of nodes, and a network drive that kept all of the software available to the clients and the server. Each Raspberry pi 3 board was identical each with one gigabyte of ram, and a quad core ARMv8 64 bit CPU running at 1.2 GHz. The Pis were connected to the network by ethernet through their gigabit ethernet port, which was then connected to a switch that was then connected to a local network where the server also resided connected via ethernet too. The server was a dell inspiron laptop running a Intel Core i7-6500U CPU @ 3.1GHz with eight gigabytes of ram. The network drive was a separate Raspberry pi 3 connected to the clients and server via sshfs. The distributed software was developed by the Student researcher, Sylvain Jones. The software can be found at https://github.com/Hashfastr/verteiltes .
op increasing the interval of computation by 1000 primes, then the amount was recorded to a data file that would be imported to a spreadsheet program to be interpreted and evaluated. The network system was looped by means of a client and a server bash script, and were synced by means of a lock file on the network drive that started the scripts simultaneously. To reduce accidental misfires, and make sure all clients were connected before collecting data the loops were set with a second delay that allowed all the clients to connect before starting the computation. The single core tests and the modern core tests were both very similar in that they just ran the program with different increasing amounts of primes to compute and recorded that to a data file. Data can be found at the software’s github, https://github.com/Hashfastr/verteiltes .
The data once delivered showed that the single core test was slower than the network test, which was slower than the modern cpu test. Although the data did show that single core tests were much faster than the network tests at very small numbers. Because of this we can determine where it becomes efficient to use a network system over a single core system.
Although unlike the modern cpu tests and the single core tests, the network tests were very unreliable and made data collection hard and possibly affected the data overall. This is because these network tests were done on a home network, not using professional equipment, and this network was shared with other people in my home, at the time, this could explain why the data is so jumpy on the network tests compared to the other tests. The fact that the tests were not using professional equipment and did not have the network alone could have even affected the computation times. Other factors could have affected the computation times, such was the cpu tests used 100% of the cpu power, while the cluster tended to only use ~20% of each core of the cluster when running. If optimized and allowed to use 100% of the cpu’s power the network tests may have beaten the modern tests in computation time, especially since the server was only using ~16% of cpu power per test. 
In the future various methods can be reapplied to the network computation model to increase the efficiency of the network applications, such as developing a base 64 number system that would compress 8 bits of data down to 4 bits, reducing the amount of data transferred and further reducing the amount the cpu has to dedicate to handling data. Another method would be optimizing the server and the client with multi-threading, so instead of running 4 clients on each pi, only one would be run and it would use as much of the cpu, all 4 cores, as possible solving allowing each client to effectively compute more than ever before, and even surpass the modern cpu test. Other optimizations include acquiring better more professional equipment than what I had could increase the efficiency and clarity of the data, seeing the amount of data travelling to from the server was ~10 megabytes a second, and ~2 megabytes a second coming in. Even improving my skills as a programming with actual professional college courses would definitely improve the efficiency of all three systems, seeing that up until now, i've only been self taught. A major future goal for the project would be to determine how much the computing power the networking model takes to run versus the modern model, and see if this could lead to a more eco-friendly way of computation.
Overall these improvements are a good future for the project. The data did not follow up with my initial hypothesis that stated that the network system would be faster than the modern and single core systems, which hinged on a 100% efficient model of the network system, which was not achieved.

